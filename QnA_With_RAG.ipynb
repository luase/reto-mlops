{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A con RAG usando modelos locales (sin ejecución de código)\n",
    "Este tipo de Chatbot es más adecuado para uso general de consultas sobre la base de datos, es decir conocimiento ya existente que no requiera código al ser ejecutado.\n",
    "Algunas preguntas de ejemplo:\n",
    "- ¿Cuántas casas a la renta tienen?\n",
    "- ¿Cuánto cuesta rentar?\n",
    "- ¿Qué hay más, casas o departamentos en renta?\n",
    "\n",
    "Tiene la ventaja de que no puede ser usado maliciosamente con intenciones de correr código sin supervisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escogemos alguna de las dos opciones para procesar inicialmente los datos: convertirlo en documentos y hacer un corte (loaded and split).\n",
    "\n",
    "La primera opción es cargarlos como un CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "csv_filepath = './data/listings.csv'\n",
    "loader = CSVLoader(csv_filepath, csv_args={\n",
    "    \"delimiter\": \",\",\n",
    "    \"fieldnames\": [\"id\", \"Listing Type\", \"Property Type\", \"Price in MXN\", \"Number of Bedrooms\", \"Number of Bathrooms\", \"Has Pool\", \"Has Terrace\", \"Surface in m2\"],\n",
    "},\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda opción sería cargarlos como un Dataframe de la librería de pandas (Esta opción es una alternativa a la anterior, escoge una u otra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "\n",
    "csv_filepath = './data/listings.csv'\n",
    "df = pd.read_csv(csv_filepath)\n",
    "loader = DataFrameLoader(df, page_content_column=\"id\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "Aquí escogemos LLM que deseamos utilizar, en este caso es **llama2**, un modelo Open Source corriendo en nuestro equipo local a través de Ollama.\n",
    "Este modelo será utilizado en la etapa de 'embedding' para la base de datos vectoriales y como LLM para nuestras queries.\n",
    "Considero importante utilizar una temperatura de 0 o cercana a él para evitar que el LLM halucine respuestas cuando desconozca los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "# Nombre del modelo\n",
    "modelo = \"llama2\"\n",
    "llm = ChatOllama(\n",
    "    model=modelo,\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de datos Vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso utilizamos Chromadb como base de datos vectorial para almacenar los datos embebidos y también recuperarlos. El siguiente proceso puede ser tardado para procesarse, sin embargo está configurado actualmente para guardar esta base de datos vectoriales tras ejecutarse la primera vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Crear el vectorstore\n",
    "embedding_model = OllamaEmbeddings(model=modelo)\n",
    "db = Chroma.from_documents(docs, embedding_model, persist_directory=\"./data\", collection_name=\"chroma_listings\")\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras haber hecho la celda anterior, es posible cargar esta db desde el directorio guardado, siendo necesario volver a ejecutar la celda de arriba solo cuando se decida cambiar el modelo o se agreguen nuevas entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Abrir el vectorstore\n",
    "embedding_model = OllamaEmbeddings(model=modelo)\n",
    "db = Chroma(persist_directory=\"./data\", embedding_function=embedding_model)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "Necesitamos definir también el template de nuestro prompt, esto nos ayuda a personalizar a la IA con respuestas más acordes a lo que estamos buscando, así como especificarle cómo usar la información previa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\"Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Chain\n",
    "Esto es la cadena de acciones que nuestro LLM tomará para responder nuestras preguntas, aquí va nuestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,\n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The average cost of buying an apartment in Mexico can vary depending on several factors such as location, size, and amenities. However, based on the data provided in the documents, the average price of an apartment in Mexico is around 3279050 MXN (approximately $164,000 USD).\\n\\nThe document with the ID \"d6ca294ae021928ff6a899645398670e\" provides the most accurate information about the average cost of an apartment in Mexico. According to this document, the average price of an apartment in Mexico is 3279050 MXN (approximately $164,000 USD).\\n\\nIt\\'s important to note that this is just an average and the cost of buying an apartment in Mexico can vary significantly depending on the location, size, and amenities of the property. For example, apartments in popular tourist areas or in major cities like Mexico City may be more expensive than those in smaller towns or rural areas. Additionally, the cost of buying an apartment can also vary depending on the type of ownership, such as freehold or leasehold.\\n\\nIn summary, based on the data provided in the documents, the average cost of buying an apartment in Mexico is around 3279050 MXN (approximately $164,000 USD). However, it\\'s important to consider other factors that can affect the cost of buying an apartment in Mexico when making a decision.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Cuanto cuesta en promedio comprar un apartamento?\"\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided documents, there are 4 houses for sale.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How many houses do you have?\"\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The range of prices for apartments in the listings is between 15,200 MXN and 15,200 MXN.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Cual es el rango de precio de los departamentos en renta?\"\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
